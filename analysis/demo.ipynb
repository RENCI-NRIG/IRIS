{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"\" rel=\"Topology\"><img src=\"../data/demo-test/topology.png\" alt=\"\" /></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1) We have pre-collected the training data. Now we are going to select one victimÂ and corrupt (cache or link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "victim is set: \n",
      "export uc-compute-c1_Link4=192.168.17.3\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#victim = \"syr-cache\"\n",
    "#victim = \"uc-router-n0_Link12\"\n",
    "victim = \"uc-compute-c1_Link4\"\n",
    "\n",
    "\n",
    "cmd = \"set_victim.sh {}\".format(victim)\n",
    "\n",
    "import subprocess\n",
    "ssh_control = \"ssh -i ~/.ssh/iris_rsa root@129.7.98.66 /root/IRIS/orchestra/\"\n",
    "args = \"{}{}\".format(ssh_control, cmd).split()\n",
    "print(subprocess.check_output(args, encoding='UTF-8', stderr=subprocess.STDOUT))\n",
    "victim = victim.replace('-','.') # to sync with what data analysis will use\n",
    "victim = victim.replace('_','.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2) Starting the workflows from 4 submit sites (Beware following sell takes 12 mins), and collect data from pagasus elastic search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cmd = \"wf_test_v2.sh\"\n",
    "\n",
    "args = \"{}{}\".format(ssh_control, cmd).split()\n",
    "print(subprocess.check_output(args, encoding='UTF-8', stderr=subprocess.STDOUT))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3) let's download the file as test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = \"01v2_02_20210909_1745PM\" # replace this\n",
    "\n",
    "remote_file = \"/var/iris_results/{}/{}_full.csv\".format(filename,filename)\n",
    "test_file = \"../data/demo-test/test.csv\"\n",
    "\n",
    "# copy the full csv and zip to local\n",
    "cmd = \"scp -i ~/.ssh/iris_rsa root@129.7.98.66:{} {}\".format(remote_file, test_file)\n",
    "subprocess.check_output( cmd.split(), encoding='UTF-8', stderr=subprocess.STDOUT)\n",
    "cmd = \"scp -i ~/.ssh/iris_rsa root@129.7.98.66:/var/iris_results/{}.tar.gz ../data/demo-test/\".format(filename)\n",
    "subprocess.check_output( cmd.split(), encoding='UTF-8', stderr=subprocess.STDOUT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4) Read the pre-collected train data and import some functions before applying to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_process(data_file, info=False):\n",
    "    input_file = data_file\n",
    "    df = pd.read_csv(input_file, header = 0)\n",
    "    #df.dropna(inplace = True) \n",
    "    df.fillna(1.0/500.0) #the corruption rate for the cache failures is all set to be \"NaN\"\n",
    "    df['corrupt_label']=df['corrupt_label'].str.replace('-','.')\n",
    "    df['flow'] = df['submit_host']+'-'+df['execution_host']\n",
    "    df['FM']=df['transfer_success']+df['checksum_success']\n",
    "    \n",
    "    df_failure = df[df.checksum_success==False]\n",
    "    df_dummy = pd.get_dummies(df_failure[['submit_host', 'execution_host','flow','transfer_success', 'checksum_success','src_label','dst_label','bytes','corrupt_rate','corrupt_label']], prefix=['submit_host', 'execution_host','src_label','dst_label','flow'], columns=['submit_host', 'execution_host','src_label','dst_label','flow'])\n",
    "    #df_dummy['bytes']=df_dummy['bytes'].str[0:-4]\n",
    "    df_dummy['bytes']=pd.to_numeric(df_dummy['bytes'], errors='coerce')\n",
    "    df_dummy['corrupt_rate']=pd.to_numeric(df_dummy['corrupt_rate'], errors='coerce')\n",
    "    df_dummy = df_dummy.replace(np.nan, 0, regex=True)\n",
    "    y_complete=df_dummy['corrupt_label']\n",
    "    X_complete=df_dummy.drop(['corrupt_label'],axis=1)\n",
    "    \n",
    "    if info:\n",
    "        original_headers = list(df.columns.values)\n",
    "        print(\"Original shape:\")\n",
    "        print(original_headers)\n",
    "        print(\"Original shape:\"+str(df.shape))\n",
    "        dummy_headers = list(df_dummy.columns.values)\n",
    "        print(\"Encoded shape:\")\n",
    "        print(dummy_headers)\n",
    "        print(str(df_dummy.shape))\n",
    "    \n",
    "    return df,df_dummy,X_complete,y_complete\n",
    "    \n",
    "    #return df,df_dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shape:\n",
      "['root_xwf_id', 'job_id', 'start_time', 'end_time', 'submit_host', 'submit_user', 'execution_host', 'execution_user', 'job_type', 'job_exit_code', 'bytes', 'lfn', 'src_label', 'src_url', 'src_proto_host', 'dst_label', 'dst_url', 'dst_proto_host', 'transfer_success', 'checksum_success', 'actual_checksum', 'expected_checksum', 'scenario', 'corrupt_label', 'corrupt_start', 'corrupt_end', 'corrupt_rate', 'flow', 'FM']\n",
      "Original shape:(45291, 29)\n",
      "Encoded shape:\n",
      "['transfer_success', 'checksum_success', 'bytes', 'corrupt_rate', 'corrupt_label', 'submit_host_syr-submit', 'submit_host_uc-submit', 'submit_host_ucsd-submit', 'submit_host_unl-submit', 'execution_host_syr-compute-c0', 'execution_host_syr-compute-c1', 'execution_host_uc-compute-c0', 'execution_host_uc-compute-c1', 'execution_host_ucsd-compute-c0', 'execution_host_ucsd-compute-c1', 'execution_host_unl-compute-c0', 'execution_host_unl-compute-c1', 'src_label_syr', 'src_label_uc', 'src_label_ucsd', 'src_label_unl', 'dst_label_syr', 'dst_label_uc', 'dst_label_ucsd', 'dst_label_unl', 'flow_syr-submit-syr-compute-c0', 'flow_syr-submit-syr-compute-c1', 'flow_syr-submit-uc-compute-c0', 'flow_syr-submit-uc-compute-c1', 'flow_syr-submit-ucsd-compute-c0', 'flow_syr-submit-ucsd-compute-c1', 'flow_syr-submit-unl-compute-c0', 'flow_syr-submit-unl-compute-c1', 'flow_uc-submit-syr-compute-c0', 'flow_uc-submit-syr-compute-c1', 'flow_uc-submit-uc-compute-c0', 'flow_uc-submit-uc-compute-c1', 'flow_uc-submit-ucsd-compute-c0', 'flow_uc-submit-ucsd-compute-c1', 'flow_uc-submit-unl-compute-c0', 'flow_uc-submit-unl-compute-c1', 'flow_ucsd-submit-syr-compute-c0', 'flow_ucsd-submit-syr-compute-c1', 'flow_ucsd-submit-uc-compute-c0', 'flow_ucsd-submit-uc-compute-c1', 'flow_ucsd-submit-ucsd-compute-c0', 'flow_ucsd-submit-ucsd-compute-c1', 'flow_ucsd-submit-unl-compute-c0', 'flow_ucsd-submit-unl-compute-c1', 'flow_unl-submit-syr-compute-c0', 'flow_unl-submit-syr-compute-c1', 'flow_unl-submit-uc-compute-c0', 'flow_unl-submit-uc-compute-c1', 'flow_unl-submit-ucsd-compute-c0', 'flow_unl-submit-ucsd-compute-c1', 'flow_unl-submit-unl-compute-c1']\n",
      "(2920, 56)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yxin/opt/anaconda3/lib/python3.8/site-packages/pandas/core/computation/expressions.py:204: UserWarning: evaluating in Python space because the '+' operator is not supported by numexpr for the bool dtype, use '|' instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#input_file = \"../data/exogeni/var/iris_results/01v2_02_20210115_0445AM/01v2_02_20210115_0445AM_full.csv\"\n",
    "input_file = \"../data/exogeni/var2/iris_results/01v2_02_20210125_1336PM/01v2_02_20210125_1336PM_full.csv\"\n",
    "df_ori,df_dummy,X_complete, y_complete=file_process(input_file,True)\n",
    "#df_ori,df_dummy=file_process(input_file,False)\n",
    "y_complete=df_dummy['corrupt_label']\n",
    "X_complete=df_dummy.drop(['corrupt_label'],axis=1)\n",
    "df_training=[df_dummy]\n",
    "\n",
    "training_dataset={\"complete\":{\"X\":X_complete,\n",
    "                 \"y\":y_complete}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shape:\n",
      "['root_xwf_id', 'job_id', 'start_time', 'end_time', 'submit_host', 'submit_user', 'execution_host', 'execution_user', 'job_type', 'job_exit_code', 'bytes', 'lfn', 'src_label', 'src_url', 'src_proto_host', 'dst_label', 'dst_url', 'dst_proto_host', 'transfer_success', 'checksum_success', 'actual_checksum', 'expected_checksum', 'scenario', 'corrupt_label', 'corrupt_start', 'corrupt_end', 'corrupt_rate', 'flow', 'FM']\n",
      "Original shape:(632, 29)\n",
      "Encoded shape:\n",
      "['transfer_success', 'checksum_success', 'bytes', 'corrupt_rate', 'corrupt_label', 'submit_host_syr-submit', 'submit_host_uc-submit', 'submit_host_ucsd-submit', 'submit_host_unl-submit', 'execution_host_uc-compute-c1', 'src_label_syr', 'src_label_uc', 'src_label_ucsd', 'src_label_unl', 'dst_label_uc', 'flow_syr-submit-uc-compute-c1', 'flow_uc-submit-uc-compute-c1', 'flow_ucsd-submit-uc-compute-c1', 'flow_unl-submit-uc-compute-c1']\n",
      "(58, 19)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yxin/opt/anaconda3/lib/python3.8/site-packages/pandas/core/computation/expressions.py:204: UserWarning: evaluating in Python space because the '+' operator is not supported by numexpr for the bool dtype, use '|' instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#test_file = \"../data/exogeni/var2/iris_results/01v2_02_20210125_1336PM/01v2_02_20210125_1336PM_full.csv\"\n",
    "#test_file = \"../data/demo-test/01v2_02_20210831_1741PM_full_syr-cache.csv\"\n",
    "#test_file = \"../data/demo-test/01v2_02_20210901_1241PM_full_uc-router-n0-link.csv\"\n",
    "test_file = \"../data/demo-test/test.csv\"\n",
    "df_t_ori,df_t_dummy,X_test, y_test=file_process(test_file,True)\n",
    "#df_t_ori,df_t_dummy=file_process(test_file,True)\n",
    "#y_test=df_t_dummy['corrupt_label']\n",
    "#X_test=df_t_dummy.drop(['corrupt_label'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def missing_feature(X_complete, X_test):\n",
    "    print(\"X_complete:\"+str(len(X_complete.columns)))\n",
    "    print(\"X_test:\" + str(len(X_test.columns)))\n",
    "    c_t_missing=[]\n",
    "    for c_c in X_complete.columns:\n",
    "        if c_c not in X_test.columns:\n",
    "            #print(c_c+\" c_c not in test!\")\n",
    "            c_t_missing.append(c_c)\n",
    "            \n",
    "    c_c_missing=[]\n",
    "    for c_t in X_test.columns:\n",
    "        if c_t not in X_complete.columns:\n",
    "            #print(c_t+\" c_t not in complete!\")\n",
    "            c_c_missing.append(c_t)\n",
    "\n",
    "    for c_c in c_t_missing:\n",
    "        #print(c_t+\" c_t dropping!\")\n",
    "        X_test[c_c]='0'\n",
    "        \n",
    "    for c_t in c_c_missing:\n",
    "        #print(c_t+\" c_t dropping!\")\n",
    "        X_test=X_test.drop(columns=c_t)\n",
    "        \n",
    "    X_complete, X_test = X_complete.align(X_test, join='inner', axis=1)\n",
    "    \n",
    "    print(\"After imputation:\"+str(len(X_test.columns)))\n",
    "    \n",
    "    return X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_complete:55\n",
      "X_test:18\n",
      "After imputation:55\n",
      "X_complete:56\n",
      "X_test:19\n",
      "After imputation:56\n"
     ]
    }
   ],
   "source": [
    "X_test = missing_feature(X_complete, X_test)\n",
    "df_t_dummy = missing_feature(df_dummy, df_t_dummy)\n",
    "\n",
    "#df_dummy,df_t_dummy = df_dummy.align(df_t_dummy, join='inner', axis=1)\n",
    "#X_complete, X_test = X_complete.align(X_test, join='inner', axis=1)\n",
    "\n",
    "df_t=[df_t_dummy]\n",
    "testing_dataset={\"testing\":{\"X\":X_test,\n",
    "                 \"y\":y_test}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(model, test_data, classes, class_label, k):\n",
    "    if(k==0): return null,null\n",
    "    num = classes.size\n",
    "    correct_class={}\n",
    "    correct=0\n",
    "    for label in classes:\n",
    "        label_pred=[]\n",
    "        isCorrect=False\n",
    "        test_data_1=test_data[test_data[class_label]==label]\n",
    "        if test_data_1.shape[0]==0:\n",
    "            print(\"No match for {}.\".format(label))\n",
    "            correct=correct+1\n",
    "            correct_class[label]=1\n",
    "            continue\n",
    "        else:\n",
    "            print(\"label {}.\".format(label))\n",
    "        x_test_1=test_data_1.drop([class_label],axis=1)\n",
    "        test_prob_1 = model.predict_proba(x_test_1)\n",
    "        label_array=test_prob_1.mean(axis=0)\n",
    "        #label_array=np.nanmean(np.where(test_rf_prob_1!=0,test_rf_prob_1,np.nan),0)\n",
    "        label_index = label_array.argmax()\n",
    "        label_index_sort = label_array.argsort()\n",
    "        #label_pred[0] = classes[label_index]\n",
    "        for j in range(0,k): \n",
    "            #print(f'j={j}, label={label_index}')\n",
    "            if(j==0):\n",
    "                label_pred.append(classes[label_index])\n",
    "            else:\n",
    "                label_pred.append(classes[label_index_sort[(-1)*j-1]])\n",
    "            #print(j,label_pred[j],label)\n",
    "            if(label==label_pred[j]):\n",
    "                isCorrect=True\n",
    "                break\n",
    "               \n",
    "        #print(label_pred)\n",
    "        #print(isCorrect)\n",
    "        if isCorrect:\n",
    "            print(\"predicted label:\"+label)\n",
    "            correct=correct+1\n",
    "            correct_class[label]=1\n",
    "        else:\n",
    "            correct_class[label]=0\n",
    "            print(\"wrong label:\"+label)\n",
    "            for j in range(0,k): \n",
    "                print(\"predicted label \"+str(j)+\":\"+label_pred[j])\n",
    "    return correct_class, correct, correct/num "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, test_data, classes, class_label):\n",
    "\n",
    "    num = classes.size\n",
    "    correct_class={}\n",
    "    correct=0\n",
    "\n",
    "    print(\"classes are {}\".format(classes))\n",
    "    #what_we_corrupted = y_test.array[0]\n",
    "    what_we_corrupted = \"{} \".format(victim)\n",
    "    print(what_we_corrupted)\n",
    "    if what_we_corrupted not in classes.tolist():\n",
    "        what_we_corrupted=victim.replace('-','.').split('.')[0]\n",
    "    print(what_we_corrupted)\n",
    "    pos = classes.tolist().index(what_we_corrupted)\n",
    "    print(\"what_we_corrupted: {}, which is at index {}\".format(what_we_corrupted, pos))\n",
    "    \n",
    "    ourlabel = [what_we_corrupted]\n",
    "    print(\"ourlabel = {}\".format(ourlabel))\n",
    "    for label in ourlabel:\n",
    "        print(\"class_label/label = {}/{}\".format(class_label,label))\n",
    "        label_pred=[]\n",
    "        isCorrect=False\n",
    "        \n",
    "        test_data_1=test_data[test_data[class_label]==label]\n",
    "        if test_data_1.shape[0]==0:\n",
    "            print(\"No match {}\".format(label))\n",
    "            correct=correct+1\n",
    "            correct_class[label]=1\n",
    "            continue\n",
    "        x_test_1=test_data_1.drop([class_label],axis=1)\n",
    "        test_prob_1 = model.predict_proba(x_test_1)\n",
    "        label_array=test_prob_1.mean(axis=0)\n",
    "        print(\"label_array = {}\".format(label_array))\n",
    "        #label_array=np.nanmean(np.where(test_rf_prob_1!=0,test_rf_prob_1,np.nan),0)\n",
    "        label_index = label_array.argmax()\n",
    "        label_index_sort = label_array.argsort()\n",
    "        rank = classes.size - label_index_sort.tolist().index(pos)\n",
    "        top_k = 3\n",
    "        if rank > 3:\n",
    "            top_k = rank\n",
    "        print(\"top_k = {}\".format(top_k))\n",
    "        for x in range (1, top_k + 1):\n",
    "            guess = classes[label_index_sort[(-1)*x]]\n",
    "            print(\"{}th prediction: {}\".format(x, guess))\n",
    "        print('\\n\"{}\" is rank {} in prediction'.format(what_we_corrupted, rank))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_dt(classifier, df, training_dataset,class_label):\n",
    "    i=0\n",
    "    for k, d in training_dataset.items():\n",
    "        X=d[\"X\"]\n",
    "        y=d['y']\n",
    "        clf = classifier\n",
    "        clf_model=clf.fit(X,y)\n",
    "        pred=clf.predict(X)\n",
    "        balanced_accu=balanced_accuracy_score(y, pred)\n",
    "        f1=f1_score(y, pred,average='weighted')\n",
    "        print(str(k)+ \"label_size:\" + str(clf.classes_.size) + \":balanced_accu=\"+str(balanced_accu)+\":F1-Score=\"+str(f1))\n",
    "        for j in range(1,4):\n",
    "            c,correct,accu=accuracy(clf_model, df[i], clf.classes_, class_label, j)\n",
    "            print(\"Top-\"+str(j)+\" Accu=\"+str(accu)) \n",
    "    return clf_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_dt(clf_model,df_t, testing_dataset,class_label):\n",
    "    i=0\n",
    "    for k, d in testing_dataset.items():\n",
    "        y_t = d['y']\n",
    "        X_t = d['X']\n",
    "        pred=clf_model.predict(X_t)\n",
    "        balanced_accu=balanced_accuracy_score(y_t, pred)\n",
    "        #f1=f1_score(y_t, pred,average='weighted')\n",
    "        #print(\":balanced_accu=\"+str(balanced_accu)+\":F1-Score=\"+str(f1))\n",
    "        for j in range(1,4):\n",
    "            c,correct,accu=accuracy(clf_model, df_t[i], clf_model.classes_,class_label,j)\n",
    "            print(\"Top-\"+str(j)+\" Accu=\"+str(accu))\n",
    "        predict(clf_model, df_t[i], clf_model.classes_,class_label)\n",
    "        i=i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn import tree\n",
    "#import graphviz \n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "from sklearn.metrics import multilabel_confusion_matrix,balanced_accuracy_score,f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Try the top-k classification with the corrupted flows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_model = train_dt(RandomForestClassifier(max_depth=20, random_state=0),df_training,training_dataset, 'corrupt_label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No match for cenic.Link12 .\n",
      "No match for cenic.Link9 .\n",
      "No match for esnet.Link1 .\n",
      "No match for esnet.Link2 .\n",
      "No match for esnet.Link22 .\n",
      "No match for esnet.Link7 .\n",
      "No match for internet2.Link14 .\n",
      "No match for internet2.Link2 .\n",
      "No match for starlight.Link24 .\n",
      "No match for starlight.Link6 .\n",
      "No match for starlight.Link7 .\n",
      "No match for starlight.Link9 .\n",
      "No match for syr.cache .\n",
      "No match for syr.compute.c0.Link26 .\n",
      "No match for syr.router.n2.Link24 .\n",
      "No match for uc.cache .\n",
      "No match for uc.compute.c0.Link3 .\n",
      "label uc.compute.c1.Link4 .\n",
      "predicted label:uc.compute.c1.Link4 \n",
      "No match for uc.router.n0.Link12 .\n",
      "No match for ucsd.cache .\n",
      "No match for ucsd.compute.c0.Link23 .\n",
      "No match for ucsd.compute.c1.Link13 .\n",
      "No match for ucsd.router.n3.Link22 .\n",
      "No match for unl.cache .\n",
      "No match for unl.compute.c1.Link16 .\n",
      "No match for unl.router.n1.Link14 .\n",
      "Top-1 Accu=1.0\n",
      "No match for cenic.Link12 .\n",
      "No match for cenic.Link9 .\n",
      "No match for esnet.Link1 .\n",
      "No match for esnet.Link2 .\n",
      "No match for esnet.Link22 .\n",
      "No match for esnet.Link7 .\n",
      "No match for internet2.Link14 .\n",
      "No match for internet2.Link2 .\n",
      "No match for starlight.Link24 .\n",
      "No match for starlight.Link6 .\n",
      "No match for starlight.Link7 .\n",
      "No match for starlight.Link9 .\n",
      "No match for syr.cache .\n",
      "No match for syr.compute.c0.Link26 .\n",
      "No match for syr.router.n2.Link24 .\n",
      "No match for uc.cache .\n",
      "No match for uc.compute.c0.Link3 .\n",
      "label uc.compute.c1.Link4 .\n",
      "predicted label:uc.compute.c1.Link4 \n",
      "No match for uc.router.n0.Link12 .\n",
      "No match for ucsd.cache .\n",
      "No match for ucsd.compute.c0.Link23 .\n",
      "No match for ucsd.compute.c1.Link13 .\n",
      "No match for ucsd.router.n3.Link22 .\n",
      "No match for unl.cache .\n",
      "No match for unl.compute.c1.Link16 .\n",
      "No match for unl.router.n1.Link14 .\n",
      "Top-2 Accu=1.0\n",
      "No match for cenic.Link12 .\n",
      "No match for cenic.Link9 .\n",
      "No match for esnet.Link1 .\n",
      "No match for esnet.Link2 .\n",
      "No match for esnet.Link22 .\n",
      "No match for esnet.Link7 .\n",
      "No match for internet2.Link14 .\n",
      "No match for internet2.Link2 .\n",
      "No match for starlight.Link24 .\n",
      "No match for starlight.Link6 .\n",
      "No match for starlight.Link7 .\n",
      "No match for starlight.Link9 .\n",
      "No match for syr.cache .\n",
      "No match for syr.compute.c0.Link26 .\n",
      "No match for syr.router.n2.Link24 .\n",
      "No match for uc.cache .\n",
      "No match for uc.compute.c0.Link3 .\n",
      "label uc.compute.c1.Link4 .\n",
      "predicted label:uc.compute.c1.Link4 \n",
      "No match for uc.router.n0.Link12 .\n",
      "No match for ucsd.cache .\n",
      "No match for ucsd.compute.c0.Link23 .\n",
      "No match for ucsd.compute.c1.Link13 .\n",
      "No match for ucsd.router.n3.Link22 .\n",
      "No match for unl.cache .\n",
      "No match for unl.compute.c1.Link16 .\n",
      "No match for unl.router.n1.Link14 .\n",
      "Top-3 Accu=1.0\n",
      "classes are ['cenic.Link12 ' 'cenic.Link9 ' 'esnet.Link1 ' 'esnet.Link2 '\n",
      " 'esnet.Link22 ' 'esnet.Link7 ' 'internet2.Link14 ' 'internet2.Link2 '\n",
      " 'starlight.Link24 ' 'starlight.Link6 ' 'starlight.Link7 '\n",
      " 'starlight.Link9 ' 'syr.cache ' 'syr.compute.c0.Link26 '\n",
      " 'syr.router.n2.Link24 ' 'uc.cache ' 'uc.compute.c0.Link3 '\n",
      " 'uc.compute.c1.Link4 ' 'uc.router.n0.Link12 ' 'ucsd.cache '\n",
      " 'ucsd.compute.c0.Link23 ' 'ucsd.compute.c1.Link13 '\n",
      " 'ucsd.router.n3.Link22 ' 'unl.cache ' 'unl.compute.c1.Link16 '\n",
      " 'unl.router.n1.Link14 ']\n",
      "uc.compute.c1.Link4 \n",
      "uc.compute.c1.Link4 \n",
      "what_we_corrupted: uc.compute.c1.Link4 , which is at index 17\n",
      "ourlabel = ['uc.compute.c1.Link4 ']\n",
      "class_label/label = corrupt_label/uc.compute.c1.Link4 \n",
      "label_array = [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 1.80865506e-01 0.00000000e+00 6.02696463e-02 0.00000000e+00\n",
      " 6.89655172e-02 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 4.46003986e-01 2.43722931e-01 0.00000000e+00\n",
      " 1.72413793e-04 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00]\n",
      "top_k = 3\n",
      "1th prediction: uc.compute.c1.Link4 \n",
      "2th prediction: uc.router.n0.Link12 \n",
      "3th prediction: esnet.Link22 \n",
      "\n",
      "\"uc.compute.c1.Link4 \" is rank 1 in prediction\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yxin/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1850: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n"
     ]
    }
   ],
   "source": [
    "test_dt(clf_model,df_t,testing_dataset, 'corrupt_label')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Let's balance the data via oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler,SMOTE, ADASYN,SMOTENC\n",
    "from imblearn.combine import SMOTEENN, SMOTETomek\n",
    "\n",
    "def train_over_sampling(classifier,df,training_dataset,class_label,test=False):\n",
    "    i=0\n",
    "    over_sampling = [RandomOverSampler(random_state=0),\n",
    "        #SMOTE(random_state=0),\n",
    "        #SMOTEENN(random_state=0),\n",
    "        #SMOTETomek(random_state=0),\n",
    "        #SMOTENC(categorical_features=[4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43], random_state=0)\n",
    "\n",
    "    ]\n",
    "    for k, d in training_dataset.items():\n",
    "        for s in range(0,len(over_sampling)):\n",
    "            X=d[\"X\"]\n",
    "            y=d['y']\n",
    "            print(\"sampling:\"+str(s)+\":\"+str(over_sampling[s]))\n",
    "            os = over_sampling[s]\n",
    "            X_resampled, y_resampled = os.fit_resample(X, y)\n",
    "            #clf = RandomForestClassifier(max_depth=20, random_state=0)\n",
    "            clf = classifier\n",
    "            clf_model=clf.fit(X_resampled, y_resampled)\n",
    "            \n",
    "            pred=clf.predict(X)\n",
    "            balanced_accu=balanced_accuracy_score(y, pred)\n",
    "            f1=f1_score(y, pred,average='weighted')\n",
    "            print(str(k)+\":balanced_accu=\"+str(balanced_accu)+\":F1-Score=\"+str(f1))\n",
    "            \n",
    "            for j in range(1,4):\n",
    "                if test:\n",
    "                    c,correct,accu=accuracy(clf_model, df_t[i], clf.classes_,class_label,j)\n",
    "                else:\n",
    "                    c,correct,accu=accuracy(clf_model, df[i], clf.classes_,class_label,j)\n",
    "                print(\"Top-\"+str(j)+\" Accu=\"+str(accu)) \n",
    "        i=i+1\n",
    "        \n",
    "    return clf_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yxin/opt/anaconda3/lib/python3.8/site-packages/pandas/core/computation/expressions.py:204: UserWarning: evaluating in Python space because the '+' operator is not supported by numexpr for the bool dtype, use '|' instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shape:\n",
      "['root_xwf_id', 'job_id', 'start_time', 'end_time', 'submit_host', 'submit_user', 'execution_host', 'execution_user', 'job_type', 'job_exit_code', 'bytes', 'lfn', 'src_label', 'src_url', 'src_proto_host', 'dst_label', 'dst_url', 'dst_proto_host', 'transfer_success', 'checksum_success', 'actual_checksum', 'expected_checksum', 'scenario', 'corrupt_label', 'corrupt_start', 'corrupt_end', 'corrupt_rate', 'flow', 'FM']\n",
      "Original shape:(45291, 29)\n",
      "Encoded shape:\n",
      "['transfer_success', 'checksum_success', 'bytes', 'corrupt_rate', 'corrupt_label', 'submit_host_syr-submit', 'submit_host_uc-submit', 'submit_host_ucsd-submit', 'submit_host_unl-submit', 'execution_host_syr-compute-c0', 'execution_host_syr-compute-c1', 'execution_host_uc-compute-c0', 'execution_host_uc-compute-c1', 'execution_host_ucsd-compute-c0', 'execution_host_ucsd-compute-c1', 'execution_host_unl-compute-c0', 'execution_host_unl-compute-c1', 'src_label_syr', 'src_label_uc', 'src_label_ucsd', 'src_label_unl', 'dst_label_syr', 'dst_label_uc', 'dst_label_ucsd', 'dst_label_unl', 'flow_syr-submit-syr-compute-c0', 'flow_syr-submit-syr-compute-c1', 'flow_syr-submit-uc-compute-c0', 'flow_syr-submit-uc-compute-c1', 'flow_syr-submit-ucsd-compute-c0', 'flow_syr-submit-ucsd-compute-c1', 'flow_syr-submit-unl-compute-c0', 'flow_syr-submit-unl-compute-c1', 'flow_uc-submit-syr-compute-c0', 'flow_uc-submit-syr-compute-c1', 'flow_uc-submit-uc-compute-c0', 'flow_uc-submit-uc-compute-c1', 'flow_uc-submit-ucsd-compute-c0', 'flow_uc-submit-ucsd-compute-c1', 'flow_uc-submit-unl-compute-c0', 'flow_uc-submit-unl-compute-c1', 'flow_ucsd-submit-syr-compute-c0', 'flow_ucsd-submit-syr-compute-c1', 'flow_ucsd-submit-uc-compute-c0', 'flow_ucsd-submit-uc-compute-c1', 'flow_ucsd-submit-ucsd-compute-c0', 'flow_ucsd-submit-ucsd-compute-c1', 'flow_ucsd-submit-unl-compute-c0', 'flow_ucsd-submit-unl-compute-c1', 'flow_unl-submit-syr-compute-c0', 'flow_unl-submit-syr-compute-c1', 'flow_unl-submit-uc-compute-c0', 'flow_unl-submit-uc-compute-c1', 'flow_unl-submit-ucsd-compute-c0', 'flow_unl-submit-ucsd-compute-c1', 'flow_unl-submit-unl-compute-c1']\n",
      "(2920, 56)\n",
      "sampling:0:RandomOverSampler(random_state=0)\n",
      "complete:balanced_accu=0.6768008140775756:F1-Score=0.47910222922070184\n",
      "label cenic.Link12 .\n",
      "predicted label:cenic.Link12 \n",
      "label cenic.Link9 .\n",
      "predicted label:cenic.Link9 \n",
      "label esnet.Link1 .\n",
      "predicted label:esnet.Link1 \n",
      "label esnet.Link2 .\n",
      "predicted label:esnet.Link2 \n",
      "label esnet.Link22 .\n",
      "predicted label:esnet.Link22 \n",
      "label esnet.Link7 .\n",
      "predicted label:esnet.Link7 \n",
      "label internet2.Link14 .\n",
      "predicted label:internet2.Link14 \n",
      "label internet2.Link2 .\n",
      "predicted label:internet2.Link2 \n",
      "label starlight.Link24 .\n",
      "predicted label:starlight.Link24 \n",
      "label starlight.Link6 .\n",
      "predicted label:starlight.Link6 \n",
      "label starlight.Link7 .\n",
      "predicted label:starlight.Link7 \n",
      "label starlight.Link9 .\n",
      "predicted label:starlight.Link9 \n",
      "label syr.cache .\n",
      "predicted label:syr.cache \n",
      "label syr.compute.c0.Link26 .\n",
      "predicted label:syr.compute.c0.Link26 \n",
      "label syr.router.n2.Link24 .\n",
      "predicted label:syr.router.n2.Link24 \n",
      "label uc.cache .\n",
      "predicted label:uc.cache \n",
      "label uc.compute.c0.Link3 .\n",
      "predicted label:uc.compute.c0.Link3 \n",
      "label uc.compute.c1.Link4 .\n",
      "predicted label:uc.compute.c1.Link4 \n",
      "label uc.router.n0.Link12 .\n",
      "predicted label:uc.router.n0.Link12 \n",
      "label ucsd.cache .\n",
      "predicted label:ucsd.cache \n",
      "label ucsd.compute.c0.Link23 .\n",
      "predicted label:ucsd.compute.c0.Link23 \n",
      "label ucsd.compute.c1.Link13 .\n",
      "predicted label:ucsd.compute.c1.Link13 \n",
      "label ucsd.router.n3.Link22 .\n",
      "predicted label:ucsd.router.n3.Link22 \n",
      "label unl.cache .\n",
      "predicted label:unl.cache \n",
      "label unl.compute.c1.Link16 .\n",
      "predicted label:unl.compute.c1.Link16 \n",
      "label unl.router.n1.Link14 .\n",
      "predicted label:unl.router.n1.Link14 \n",
      "Top-1 Accu=1.0\n",
      "label cenic.Link12 .\n",
      "predicted label:cenic.Link12 \n",
      "label cenic.Link9 .\n",
      "predicted label:cenic.Link9 \n",
      "label esnet.Link1 .\n",
      "predicted label:esnet.Link1 \n",
      "label esnet.Link2 .\n",
      "predicted label:esnet.Link2 \n",
      "label esnet.Link22 .\n",
      "predicted label:esnet.Link22 \n",
      "label esnet.Link7 .\n",
      "predicted label:esnet.Link7 \n",
      "label internet2.Link14 .\n",
      "predicted label:internet2.Link14 \n",
      "label internet2.Link2 .\n",
      "predicted label:internet2.Link2 \n",
      "label starlight.Link24 .\n",
      "predicted label:starlight.Link24 \n",
      "label starlight.Link6 .\n",
      "predicted label:starlight.Link6 \n",
      "label starlight.Link7 .\n",
      "predicted label:starlight.Link7 \n",
      "label starlight.Link9 .\n",
      "predicted label:starlight.Link9 \n",
      "label syr.cache .\n",
      "predicted label:syr.cache \n",
      "label syr.compute.c0.Link26 .\n",
      "predicted label:syr.compute.c0.Link26 \n",
      "label syr.router.n2.Link24 .\n",
      "predicted label:syr.router.n2.Link24 \n",
      "label uc.cache .\n",
      "predicted label:uc.cache \n",
      "label uc.compute.c0.Link3 .\n",
      "predicted label:uc.compute.c0.Link3 \n",
      "label uc.compute.c1.Link4 .\n",
      "predicted label:uc.compute.c1.Link4 \n",
      "label uc.router.n0.Link12 .\n",
      "predicted label:uc.router.n0.Link12 \n",
      "label ucsd.cache .\n",
      "predicted label:ucsd.cache \n",
      "label ucsd.compute.c0.Link23 .\n",
      "predicted label:ucsd.compute.c0.Link23 \n",
      "label ucsd.compute.c1.Link13 .\n",
      "predicted label:ucsd.compute.c1.Link13 \n",
      "label ucsd.router.n3.Link22 .\n",
      "predicted label:ucsd.router.n3.Link22 \n",
      "label unl.cache .\n",
      "predicted label:unl.cache \n",
      "label unl.compute.c1.Link16 .\n",
      "predicted label:unl.compute.c1.Link16 \n",
      "label unl.router.n1.Link14 .\n",
      "predicted label:unl.router.n1.Link14 \n",
      "Top-2 Accu=1.0\n",
      "label cenic.Link12 .\n",
      "predicted label:cenic.Link12 \n",
      "label cenic.Link9 .\n",
      "predicted label:cenic.Link9 \n",
      "label esnet.Link1 .\n",
      "predicted label:esnet.Link1 \n",
      "label esnet.Link2 .\n",
      "predicted label:esnet.Link2 \n",
      "label esnet.Link22 .\n",
      "predicted label:esnet.Link22 \n",
      "label esnet.Link7 .\n",
      "predicted label:esnet.Link7 \n",
      "label internet2.Link14 .\n",
      "predicted label:internet2.Link14 \n",
      "label internet2.Link2 .\n",
      "predicted label:internet2.Link2 \n",
      "label starlight.Link24 .\n",
      "predicted label:starlight.Link24 \n",
      "label starlight.Link6 .\n",
      "predicted label:starlight.Link6 \n",
      "label starlight.Link7 .\n",
      "predicted label:starlight.Link7 \n",
      "label starlight.Link9 .\n",
      "predicted label:starlight.Link9 \n",
      "label syr.cache .\n",
      "predicted label:syr.cache \n",
      "label syr.compute.c0.Link26 .\n",
      "predicted label:syr.compute.c0.Link26 \n",
      "label syr.router.n2.Link24 .\n",
      "predicted label:syr.router.n2.Link24 \n",
      "label uc.cache .\n",
      "predicted label:uc.cache \n",
      "label uc.compute.c0.Link3 .\n",
      "predicted label:uc.compute.c0.Link3 \n",
      "label uc.compute.c1.Link4 .\n",
      "predicted label:uc.compute.c1.Link4 \n",
      "label uc.router.n0.Link12 .\n",
      "predicted label:uc.router.n0.Link12 \n",
      "label ucsd.cache .\n",
      "predicted label:ucsd.cache \n",
      "label ucsd.compute.c0.Link23 .\n",
      "predicted label:ucsd.compute.c0.Link23 \n",
      "label ucsd.compute.c1.Link13 .\n",
      "predicted label:ucsd.compute.c1.Link13 \n",
      "label ucsd.router.n3.Link22 .\n",
      "predicted label:ucsd.router.n3.Link22 \n",
      "label unl.cache .\n",
      "predicted label:unl.cache \n",
      "label unl.compute.c1.Link16 .\n",
      "predicted label:unl.compute.c1.Link16 \n",
      "label unl.router.n1.Link14 .\n",
      "predicted label:unl.router.n1.Link14 \n",
      "Top-3 Accu=1.0\n"
     ]
    }
   ],
   "source": [
    "#df_ori,df_dummy=file_process(input_file,True)\n",
    "#y_complete=df_dummy['corrupt_label']\n",
    "#X_complete=df_dummy.drop(['corrupt_label'],axis=1)\n",
    "\n",
    "df_ori,df_dummy,X_complete, y_complete=file_process(input_file,True)\n",
    "df=[df_dummy]\n",
    "\n",
    "training_dataset={\"complete\":{\"X\":X_complete,\n",
    "                 \"y\":y_complete}}\n",
    "\n",
    "clf_model = train_over_sampling(RandomForestClassifier(max_depth=20, random_state=0),df,training_dataset, 'corrupt_label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No match for cenic.Link12 .\n",
      "No match for cenic.Link9 .\n",
      "No match for esnet.Link1 .\n",
      "No match for esnet.Link2 .\n",
      "No match for esnet.Link22 .\n",
      "No match for esnet.Link7 .\n",
      "No match for internet2.Link14 .\n",
      "No match for internet2.Link2 .\n",
      "No match for starlight.Link24 .\n",
      "No match for starlight.Link6 .\n",
      "No match for starlight.Link7 .\n",
      "No match for starlight.Link9 .\n",
      "No match for syr.cache .\n",
      "No match for syr.compute.c0.Link26 .\n",
      "No match for syr.router.n2.Link24 .\n",
      "No match for uc.cache .\n",
      "No match for uc.compute.c0.Link3 .\n",
      "label uc.compute.c1.Link4 .\n",
      "predicted label:uc.compute.c1.Link4 \n",
      "No match for uc.router.n0.Link12 .\n",
      "No match for ucsd.cache .\n",
      "No match for ucsd.compute.c0.Link23 .\n",
      "No match for ucsd.compute.c1.Link13 .\n",
      "No match for ucsd.router.n3.Link22 .\n",
      "No match for unl.cache .\n",
      "No match for unl.compute.c1.Link16 .\n",
      "No match for unl.router.n1.Link14 .\n",
      "Top-1 Accu=1.0\n",
      "No match for cenic.Link12 .\n",
      "No match for cenic.Link9 .\n",
      "No match for esnet.Link1 .\n",
      "No match for esnet.Link2 .\n",
      "No match for esnet.Link22 .\n",
      "No match for esnet.Link7 .\n",
      "No match for internet2.Link14 .\n",
      "No match for internet2.Link2 .\n",
      "No match for starlight.Link24 .\n",
      "No match for starlight.Link6 .\n",
      "No match for starlight.Link7 .\n",
      "No match for starlight.Link9 .\n",
      "No match for syr.cache .\n",
      "No match for syr.compute.c0.Link26 .\n",
      "No match for syr.router.n2.Link24 .\n",
      "No match for uc.cache .\n",
      "No match for uc.compute.c0.Link3 .\n",
      "label uc.compute.c1.Link4 .\n",
      "predicted label:uc.compute.c1.Link4 \n",
      "No match for uc.router.n0.Link12 .\n",
      "No match for ucsd.cache .\n",
      "No match for ucsd.compute.c0.Link23 .\n",
      "No match for ucsd.compute.c1.Link13 .\n",
      "No match for ucsd.router.n3.Link22 .\n",
      "No match for unl.cache .\n",
      "No match for unl.compute.c1.Link16 .\n",
      "No match for unl.router.n1.Link14 .\n",
      "Top-2 Accu=1.0\n",
      "No match for cenic.Link12 .\n",
      "No match for cenic.Link9 .\n",
      "No match for esnet.Link1 .\n",
      "No match for esnet.Link2 .\n",
      "No match for esnet.Link22 .\n",
      "No match for esnet.Link7 .\n",
      "No match for internet2.Link14 .\n",
      "No match for internet2.Link2 .\n",
      "No match for starlight.Link24 .\n",
      "No match for starlight.Link6 .\n",
      "No match for starlight.Link7 .\n",
      "No match for starlight.Link9 .\n",
      "No match for syr.cache .\n",
      "No match for syr.compute.c0.Link26 .\n",
      "No match for syr.router.n2.Link24 .\n",
      "No match for uc.cache .\n",
      "No match for uc.compute.c0.Link3 .\n",
      "label uc.compute.c1.Link4 .\n",
      "predicted label:uc.compute.c1.Link4 \n",
      "No match for uc.router.n0.Link12 .\n",
      "No match for ucsd.cache .\n",
      "No match for ucsd.compute.c0.Link23 .\n",
      "No match for ucsd.compute.c1.Link13 .\n",
      "No match for ucsd.router.n3.Link22 .\n",
      "No match for unl.cache .\n",
      "No match for unl.compute.c1.Link16 .\n",
      "No match for unl.router.n1.Link14 .\n",
      "Top-3 Accu=1.0\n",
      "classes are ['cenic.Link12 ' 'cenic.Link9 ' 'esnet.Link1 ' 'esnet.Link2 '\n",
      " 'esnet.Link22 ' 'esnet.Link7 ' 'internet2.Link14 ' 'internet2.Link2 '\n",
      " 'starlight.Link24 ' 'starlight.Link6 ' 'starlight.Link7 '\n",
      " 'starlight.Link9 ' 'syr.cache ' 'syr.compute.c0.Link26 '\n",
      " 'syr.router.n2.Link24 ' 'uc.cache ' 'uc.compute.c0.Link3 '\n",
      " 'uc.compute.c1.Link4 ' 'uc.router.n0.Link12 ' 'ucsd.cache '\n",
      " 'ucsd.compute.c0.Link23 ' 'ucsd.compute.c1.Link13 '\n",
      " 'ucsd.router.n3.Link22 ' 'unl.cache ' 'unl.compute.c1.Link16 '\n",
      " 'unl.router.n1.Link14 ']\n",
      "uc.compute.c1.Link4 \n",
      "uc.compute.c1.Link4 \n",
      "what_we_corrupted: uc.compute.c1.Link4 , which is at index 17\n",
      "ourlabel = ['uc.compute.c1.Link4 ']\n",
      "class_label/label = corrupt_label/uc.compute.c1.Link4 \n",
      "label_array = [0.         0.         0.         0.         0.15954781 0.\n",
      " 0.0616719  0.         0.06896552 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.48222784\n",
      " 0.22758693 0.         0.         0.         0.         0.\n",
      " 0.         0.        ]\n",
      "top_k = 3\n",
      "1th prediction: uc.compute.c1.Link4 \n",
      "2th prediction: uc.router.n0.Link12 \n",
      "3th prediction: esnet.Link22 \n",
      "\n",
      "\"uc.compute.c1.Link4 \" is rank 1 in prediction\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yxin/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1850: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n"
     ]
    }
   ],
   "source": [
    "test_dt(clf_model,df_t,testing_dataset, 'corrupt_label')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Try the coarser per-site classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#count the number of labels in the data and the number of labels that actually caused errors.\n",
    "def num_label(df, df_dummy, site):\n",
    "    site_ori = df[site]\n",
    "    counter_site = Counter(site_ori)\n",
    "    print(\"original num_label:\" + str(len(counter_site)))\n",
    "    #for k,v in counter_site.items():\n",
    "    #    print(k)\n",
    "    \n",
    "    site_dummy = df_dummy[site]\n",
    "    counter_site_dummy = Counter(site_dummy)\n",
    "    print(\"recorded num_label:\" + str(len(counter_site_dummy)))\n",
    "\n",
    "    site_name = df[site].str.split('.', n=1, expand = True)\n",
    "    site_dummy_name = df[site].str.split('.', n=1, expand = True)\n",
    "    \n",
    "    return counter_site, counter_site_dummy,site_name,site_dummy_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original num_label:49\n",
      "recorded num_label:26\n",
      "completelabel_size:8:balanced_accu=0.6093384531968332:F1-Score=0.6106753029121078\n",
      "label cenic.\n",
      "predicted label:cenic\n",
      "label esnet.\n",
      "predicted label:esnet\n",
      "label internet2.\n",
      "predicted label:internet2\n",
      "label starlight.\n",
      "predicted label:starlight\n",
      "label syr.\n",
      "predicted label:syr\n",
      "label uc.\n",
      "predicted label:uc\n",
      "label ucsd.\n",
      "predicted label:ucsd\n",
      "label unl.\n",
      "predicted label:unl\n",
      "Top-1 Accu=1.0\n",
      "label cenic.\n",
      "predicted label:cenic\n",
      "label esnet.\n",
      "predicted label:esnet\n",
      "label internet2.\n",
      "predicted label:internet2\n",
      "label starlight.\n",
      "predicted label:starlight\n",
      "label syr.\n",
      "predicted label:syr\n",
      "label uc.\n",
      "predicted label:uc\n",
      "label ucsd.\n",
      "predicted label:ucsd\n",
      "label unl.\n",
      "predicted label:unl\n",
      "Top-2 Accu=1.0\n",
      "label cenic.\n",
      "predicted label:cenic\n",
      "label esnet.\n",
      "predicted label:esnet\n",
      "label internet2.\n",
      "predicted label:internet2\n",
      "label starlight.\n",
      "predicted label:starlight\n",
      "label syr.\n",
      "predicted label:syr\n",
      "label uc.\n",
      "predicted label:uc\n",
      "label ucsd.\n",
      "predicted label:ucsd\n",
      "label unl.\n",
      "predicted label:unl\n",
      "Top-3 Accu=1.0\n"
     ]
    }
   ],
   "source": [
    "counter_site,counter_site_dummy,site_name,site_dummy_name=num_label(df_ori,df_dummy,'corrupt_label')\n",
    "df_ori['site'] = site_name[0]\n",
    "df_dummy['site'] = site_dummy_name[0]\n",
    "df_dummy=df_dummy.drop(['corrupt_label'],axis=1)\n",
    "y_complete=df_dummy['site']\n",
    "X_complete=df_dummy.drop(['site'],axis=1)\n",
    "\n",
    "df=[df_dummy]\n",
    "    \n",
    "training_dataset={\"complete\":{\"X\":X_complete,\n",
    "                 \"y\":y_complete}}\n",
    "\n",
    "site_model = train_dt(RandomForestClassifier(max_depth=20, random_state=0),df,training_dataset, 'site')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original num_label:1\n",
      "recorded num_label:1\n",
      "No match for cenic.\n",
      "No match for esnet.\n",
      "No match for internet2.\n",
      "No match for starlight.\n",
      "No match for syr.\n",
      "label uc.\n",
      "predicted label:uc\n",
      "No match for ucsd.\n",
      "No match for unl.\n",
      "Top-1 Accu=1.0\n",
      "No match for cenic.\n",
      "No match for esnet.\n",
      "No match for internet2.\n",
      "No match for starlight.\n",
      "No match for syr.\n",
      "label uc.\n",
      "predicted label:uc\n",
      "No match for ucsd.\n",
      "No match for unl.\n",
      "Top-2 Accu=1.0\n",
      "No match for cenic.\n",
      "No match for esnet.\n",
      "No match for internet2.\n",
      "No match for starlight.\n",
      "No match for syr.\n",
      "label uc.\n",
      "predicted label:uc\n",
      "No match for ucsd.\n",
      "No match for unl.\n",
      "Top-3 Accu=1.0\n",
      "classes are ['cenic' 'esnet' 'internet2' 'starlight' 'syr' 'uc' 'ucsd' 'unl']\n",
      "uc.compute.c1.Link4 \n",
      "uc\n",
      "what_we_corrupted: uc, which is at index 5\n",
      "ourlabel = ['uc']\n",
      "class_label/label = site/uc\n",
      "label_array = [0.         0.18086551 0.06026965 0.06896552 0.         0.68989933\n",
      " 0.         0.        ]\n",
      "top_k = 3\n",
      "1th prediction: uc\n",
      "2th prediction: esnet\n",
      "3th prediction: starlight\n",
      "\n",
      "\"uc\" is rank 1 in prediction\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yxin/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1850: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n"
     ]
    }
   ],
   "source": [
    "counter_site_t,counter_site_t_dummy,site_t_name,site_t_dummy_name=num_label(df_t_ori,df_t_dummy,'corrupt_label')\n",
    "df_t_ori['site'] = site_t_name[0]\n",
    "df_t_dummy['site'] = site_t_dummy_name[0]\n",
    "if 'corrupt_label' in df_t_dummy:\n",
    "    df_t_dummy=df_t_dummy.drop(['corrupt_label'],axis=1)\n",
    "y_t=df_t_dummy['site']\n",
    "X_t=df_t_dummy.drop(['site'],axis=1)\n",
    "\n",
    "df_t=[df_t_dummy]\n",
    "    \n",
    "testing_dataset={\"complete\":{\"X\":X_t,\n",
    "                 \"y\":y_t}}\n",
    "test_dt(site_model,df_t,testing_dataset, 'site')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. try the probability based model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prob_dict(df_c,group):\n",
    "    target_flow=df_c[group]\n",
    "    counter_flow = Counter(target_flow)\n",
    "    flow_prob_dict={}\n",
    "    for i,j in counter_flow.items():\n",
    "    #print(i+\":\"+str(j)+\":\"+str(len(target_flow)))\n",
    "        per_flow = j / len(target_flow) * 100\n",
    "        #print('flow=%s, Count=%d, Per__flow=%.3f%%' % (i, j, per_flow))\n",
    "        df_flow=df_c[(df_c[group]==i)]\n",
    "        flow_count=df_flow['checksum_success'].value_counts(normalize=True)\n",
    "        #print(flow_count.index.tolist())\n",
    "        #print(flow_count.values.tolist())\n",
    "        flow_count_dict=flow_count.to_dict()\n",
    "        #print(flow_count_dict)\n",
    "        i_group=group+\"_\"+i\n",
    "        if 0 in flow_count_dict:\n",
    "            flow_prob_dict[i_group]=flow_count_dict[0]\n",
    "        else:\n",
    "            flow_prob_dict[i_group]=0\n",
    "        #print(\"{}:{}\".format(i,flow_prob_dict[i]))\n",
    "    return flow_prob_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_prob_dict(df, target_name,groups):\n",
    "    # summarize the class distribution\n",
    "    #target = df.values[:,-5]\n",
    "    target = df[target_name]\n",
    "    counter = Counter(target)\n",
    "    label_prob_dict={}\n",
    "    for k,v in counter.items():\n",
    "        per = v / len(target) * 100\n",
    "        #print('Class=%s, Count=%d, Percentage=%.3f%%' % (k, v, per))\n",
    "        df_c=df[(df[target_name]==k)]\n",
    "        flow_prob_dict={}\n",
    "        for group in groups:\n",
    "            prob=prob_dict(df_c,group)\n",
    "            flow_prob_dict={**flow_prob_dict,**prob}\n",
    "        \n",
    "        label_prob_dict[k]=flow_prob_dict\n",
    "    return label_prob_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yxin/opt/anaconda3/lib/python3.8/site-packages/pandas/core/computation/expressions.py:204: UserWarning: evaluating in Python space because the '+' operator is not supported by numexpr for the bool dtype, use '|' instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shape:\n",
      "['root_xwf_id', 'job_id', 'start_time', 'end_time', 'submit_host', 'submit_user', 'execution_host', 'execution_user', 'job_type', 'job_exit_code', 'bytes', 'lfn', 'src_label', 'src_url', 'src_proto_host', 'dst_label', 'dst_url', 'dst_proto_host', 'transfer_success', 'checksum_success', 'actual_checksum', 'expected_checksum', 'scenario', 'corrupt_label', 'corrupt_start', 'corrupt_end', 'corrupt_rate', 'flow', 'FM']\n",
      "Original shape:(45291, 29)\n",
      "Encoded shape:\n",
      "['transfer_success', 'checksum_success', 'bytes', 'corrupt_rate', 'corrupt_label', 'submit_host_syr-submit', 'submit_host_uc-submit', 'submit_host_ucsd-submit', 'submit_host_unl-submit', 'execution_host_syr-compute-c0', 'execution_host_syr-compute-c1', 'execution_host_uc-compute-c0', 'execution_host_uc-compute-c1', 'execution_host_ucsd-compute-c0', 'execution_host_ucsd-compute-c1', 'execution_host_unl-compute-c0', 'execution_host_unl-compute-c1', 'src_label_syr', 'src_label_uc', 'src_label_ucsd', 'src_label_unl', 'dst_label_syr', 'dst_label_uc', 'dst_label_ucsd', 'dst_label_unl', 'flow_syr-submit-syr-compute-c0', 'flow_syr-submit-syr-compute-c1', 'flow_syr-submit-uc-compute-c0', 'flow_syr-submit-uc-compute-c1', 'flow_syr-submit-ucsd-compute-c0', 'flow_syr-submit-ucsd-compute-c1', 'flow_syr-submit-unl-compute-c0', 'flow_syr-submit-unl-compute-c1', 'flow_uc-submit-syr-compute-c0', 'flow_uc-submit-syr-compute-c1', 'flow_uc-submit-uc-compute-c0', 'flow_uc-submit-uc-compute-c1', 'flow_uc-submit-ucsd-compute-c0', 'flow_uc-submit-ucsd-compute-c1', 'flow_uc-submit-unl-compute-c0', 'flow_uc-submit-unl-compute-c1', 'flow_ucsd-submit-syr-compute-c0', 'flow_ucsd-submit-syr-compute-c1', 'flow_ucsd-submit-uc-compute-c0', 'flow_ucsd-submit-uc-compute-c1', 'flow_ucsd-submit-ucsd-compute-c0', 'flow_ucsd-submit-ucsd-compute-c1', 'flow_ucsd-submit-unl-compute-c0', 'flow_ucsd-submit-unl-compute-c1', 'flow_unl-submit-syr-compute-c0', 'flow_unl-submit-syr-compute-c1', 'flow_unl-submit-uc-compute-c0', 'flow_unl-submit-uc-compute-c1', 'flow_unl-submit-ucsd-compute-c0', 'flow_unl-submit-ucsd-compute-c1', 'flow_unl-submit-unl-compute-c1']\n",
      "(2920, 56)\n"
     ]
    }
   ],
   "source": [
    "df_ori,df_dummy,X_complete, y_complete=file_process(input_file,True)\n",
    "groups=[\"flow\",\"src_label\",\"dst_label\"]\n",
    "label_prob_dict=generate_prob_dict(df_ori,\"corrupt_label\",groups)\n",
    "df_prob = pd.DataFrame.from_dict(label_prob_dict, orient='index')\n",
    "df_prob = df_prob.fillna(0)\n",
    "df_prob = df_prob[(df_prob.T !=0).any()] #drop rows with all zeros: no corruption labels\n",
    "df_prob=df_prob.sort_index() #sort the index\n",
    "X=df_prob.to_numpy()\n",
    "X=np.nan_to_num(X)\n",
    "#print(X)\n",
    "y=df_prob.index\n",
    "#print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_prob = RandomForestClassifier(max_depth=20, random_state=0)\n",
    "clf_prob.fit(X,y)\n",
    "clf_prob.score(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shape:\n",
      "['root_xwf_id', 'job_id', 'start_time', 'end_time', 'submit_host', 'submit_user', 'execution_host', 'execution_user', 'job_type', 'job_exit_code', 'bytes', 'lfn', 'src_label', 'src_url', 'src_proto_host', 'dst_label', 'dst_url', 'dst_proto_host', 'transfer_success', 'checksum_success', 'actual_checksum', 'expected_checksum', 'scenario', 'corrupt_label', 'corrupt_start', 'corrupt_end', 'corrupt_rate', 'flow', 'FM']\n",
      "Original shape:(632, 29)\n",
      "Encoded shape:\n",
      "['transfer_success', 'checksum_success', 'bytes', 'corrupt_rate', 'corrupt_label', 'submit_host_syr-submit', 'submit_host_uc-submit', 'submit_host_ucsd-submit', 'submit_host_unl-submit', 'execution_host_uc-compute-c1', 'src_label_syr', 'src_label_uc', 'src_label_ucsd', 'src_label_unl', 'dst_label_uc', 'flow_syr-submit-uc-compute-c1', 'flow_uc-submit-uc-compute-c1', 'flow_ucsd-submit-uc-compute-c1', 'flow_unl-submit-uc-compute-c1']\n",
      "(58, 19)\n",
      "X_complete:29\n",
      "X_test:29\n",
      "After imputation:29\n",
      "X_complete:56\n",
      "X_test:19\n",
      "After imputation:56\n",
      "X_complete:40\n",
      "X_test:37\n",
      "After imputation:40\n",
      "(1, 40)\n",
      "(1, 40)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yxin/opt/anaconda3/lib/python3.8/site-packages/pandas/core/computation/expressions.py:204: UserWarning: evaluating in Python space because the '+' operator is not supported by numexpr for the bool dtype, use '|' instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_t_ori,df_t_dummy,X_t_complete, y_t_complete=file_process(test_file,True)\n",
    "df_t_ori = missing_feature(df_ori, df_t_ori)\n",
    "df_t_dummy = missing_feature(df_dummy, df_t_dummy)\n",
    "groups=[\"flow\",\"src_label\",\"dst_label\"]\n",
    "label_prob_dict_test=generate_prob_dict(df_t_ori,\"corrupt_label\",groups)\n",
    "df_prob_test = pd.DataFrame.from_dict(label_prob_dict_test, orient='index')\n",
    "\n",
    "df_prob_test = missing_feature(df_prob, df_prob_test)\n",
    "\n",
    "df_prob_test = df_prob_test.fillna(0)\n",
    "df_prob_test = df_prob_test[(df_prob_test.T !=0).any()] #drop rows with all zeros: no corruption labels\n",
    "#df_prob,df_prob_test = df_prob.align(df_prob_test, join='inner', axis=1)\n",
    "df_prob_test = df_prob_test.sort_index() #sort the table index\n",
    "\n",
    "X_t=df_prob_test.to_numpy()\n",
    "print(X_t.shape)\n",
    "X_t=np.nan_to_num(X_t)\n",
    "print(X_t.shape)\n",
    "y_t=df_prob_test.index\n",
    "#print(y.shape)\n",
    "clf_prob.score(X_t,y_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['uc.compute.c1.Link4 '], dtype=object)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_prob.predict([X_t[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'uc.compute.c1.Link4 '"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_t[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
