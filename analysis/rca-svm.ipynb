{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input_file = \"output_20191008_0336AM.csv\" #complete\n",
    "#input_file = \"output_20191116_1256PM.csv\" #partial\n",
    "input_file = \"output_20200219_2125PM.csv\" #double\n",
    "df = pd.read_csv(input_file, header = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['FLOW'] = df['SRCNODE']+'-'+df['DESTNODE']\n",
    "df['FM']=df['FAILURE']+df['MISSING']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_failure = df[ (df.FM==1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "from sklearn.calibration import CalibratedClassifierCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dummy = pd.get_dummies(df_failure[['SRCNODE', 'DESTNODE','FM','RETRIES','LABEL']], prefix=['SRC', 'DEST'], columns=['SRCNODE', 'DESTNODE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=df_failure['LABEL']\n",
    "x=df_dummy.drop(['LABEL'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_svc=svm.LinearSVC(random_state=0)\n",
    "lin_clf=linear_svc.fit(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "cal_svc=CalibratedClassifierCV(base_estimator=linear_svc,cv=\"prefit\")\n",
    "cal_clf=cal_svc.fit(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10.5 s, sys: 43.6 ms, total: 10.6 s\n",
      "Wall time: 10.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ovo_lin_model=OneVsOneClassifier(svm.LinearSVC(random_state=0)).fit(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 52.5 s, sys: 1.45 s, total: 53.9 s\n",
      "Wall time: 17.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#svm_pred=svm_model.predict(x)\n",
    "lin_df = ovo_lin_model.decision_function(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(model, test_data, classes, k):\n",
    "    if(k==0): return null,null\n",
    "    num = classes.size\n",
    "    correct=0\n",
    "    for label in classes:\n",
    "        label_pred=[]\n",
    "        isCorrect=False\n",
    "        test_data_1=test_data[test_data.LABEL==label]\n",
    "        x_test_1=test_data_1.drop(['LABEL'],axis=1)\n",
    "        test_prob_1 = model.predict_proba(x_test_1)\n",
    "        label_array=test_prob_1.mean(axis=0)\n",
    "        #label_array=np.nanmean(np.where(test_rf_prob_1!=0,test_rf_prob_1,np.nan),0)\n",
    "        label_index = label_array.argmax()\n",
    "        label_index_sort = label_array.argsort()\n",
    "        #label_pred[0] = classes[label_index]\n",
    "        for j in range(0,k): \n",
    "            if(j==0):\n",
    "                label_pred.append(classes[label_index])\n",
    "            else:\n",
    "                label_pred.append(classes[label_index_sort[(-1)*j-1]])\n",
    "            #print(j,label_pred[j],label)\n",
    "            if(label==label_pred[j]):\n",
    "                isCorrect=True\n",
    "                break\n",
    "               \n",
    "        #print(label_pred)\n",
    "        #print(isCorrect)\n",
    "        if isCorrect:\n",
    "            correct=correct+1\n",
    "    return correct, correct/num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 0.6060606060606061)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c,r=accuracy(cal_clf, df_dummy, ovo_lin_model.classes_,1)\n",
    "c,r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2463278028318829\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yxin/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.3680773409448971"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import multilabel_confusion_matrix,balanced_accuracy_score,f1_score\n",
    "y_pred_rf = cal_clf.predict(x)\n",
    "print(balanced_accuracy_score(y, y_pred_rf))\n",
    "f1_score(y, y_pred_rf,average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c,r=accuracy(lin_df, df_dummy, ovo_lin_model.classes_,10)\n",
    "c,r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ovo_svm_model=OneVsOneClassifier(svm.SVC(random_state=0)).fit(x, y)\n",
    "#svm_pred=svm_model.predict(x)\n",
    "svm_df = ovo_svm_model.decision_function(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_ori(model, test_data, classes):\n",
    "    num = classes.size\n",
    "    correct=0\n",
    "    for label in classes:\n",
    "        test_data_1=test_data[test_data.LABEL==label]\n",
    "        x_test_1=test_data_1.drop(['LABEL'],axis=1)\n",
    "        test_prob_1 = model.decision_function(x_test_1)\n",
    "        label_index=test_prob_1.sum(axis=0).argmax()\n",
    "        label_pred = classes[label_index]\n",
    "        if(label==label_pred):\n",
    "            correct=correct+1\n",
    "    return correct, correct/num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'decision_function'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-fdf71cdf11c1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maccuracy_ori\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlin_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_dummy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0movo_lin_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-13faac36e5c0>\u001b[0m in \u001b[0;36maccuracy_ori\u001b[0;34m(model, test_data, classes)\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mtest_data_1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLABEL\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mx_test_1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_data_1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'LABEL'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mtest_prob_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mlabel_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_prob_1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mlabel_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'decision_function'"
     ]
    }
   ],
   "source": [
    "c,r=accuracy_ori(lin_df, df_dummy, ovo_lin_model.classes_)\n",
    "c,r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import multilabel_confusion_matrix,balanced_accuracy_score,f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[26755,     0],\n",
       "        [  156,     0]],\n",
       "\n",
       "       [[26252,   118],\n",
       "        [   95,   446]],\n",
       "\n",
       "       [[26589,     0],\n",
       "        [  322,     0]],\n",
       "\n",
       "       [[26794,     0],\n",
       "        [  117,     0]],\n",
       "\n",
       "       [[26061,    31],\n",
       "        [  386,   433]],\n",
       "\n",
       "       [[25767,   707],\n",
       "        [  238,   199]],\n",
       "\n",
       "       [[25509,   277],\n",
       "        [  633,   492]],\n",
       "\n",
       "       [[26900,     0],\n",
       "        [   11,     0]],\n",
       "\n",
       "       [[25812,   732],\n",
       "        [  158,   209]],\n",
       "\n",
       "       [[26900,     0],\n",
       "        [   11,     0]],\n",
       "\n",
       "       [[26900,     0],\n",
       "        [   11,     0]],\n",
       "\n",
       "       [[25994,   535],\n",
       "        [  190,   192]],\n",
       "\n",
       "       [[24880,  1061],\n",
       "        [  155,   815]],\n",
       "\n",
       "       [[26900,     0],\n",
       "        [   11,     0]],\n",
       "\n",
       "       [[26013,   271],\n",
       "        [  512,   115]],\n",
       "\n",
       "       [[26479,    92],\n",
       "        [  286,    54]],\n",
       "\n",
       "       [[26085,   416],\n",
       "        [  272,   138]],\n",
       "\n",
       "       [[26900,     0],\n",
       "        [   11,     0]],\n",
       "\n",
       "       [[26900,     0],\n",
       "        [   11,     0]],\n",
       "\n",
       "       [[25889,   635],\n",
       "        [  212,   175]],\n",
       "\n",
       "       [[26037,   476],\n",
       "        [  215,   183]],\n",
       "\n",
       "       [[26820,     0],\n",
       "        [   91,     0]],\n",
       "\n",
       "       [[26487,     0],\n",
       "        [  424,     0]],\n",
       "\n",
       "       [[25959,   596],\n",
       "        [  217,   139]],\n",
       "\n",
       "       [[25206,   445],\n",
       "        [  619,   641]],\n",
       "\n",
       "       [[25977,   124],\n",
       "        [  377,   433]],\n",
       "\n",
       "       [[26624,   116],\n",
       "        [   93,    78]],\n",
       "\n",
       "       [[25506,   637],\n",
       "        [  187,   581]],\n",
       "\n",
       "       [[26262,   298],\n",
       "        [  230,   121]],\n",
       "\n",
       "       [[26509,     0],\n",
       "        [  402,     0]],\n",
       "\n",
       "       [[26571,     0],\n",
       "        [  340,     0]],\n",
       "\n",
       "       [[26133,   379],\n",
       "        [  268,   131]],\n",
       "\n",
       "       [[25486,   233],\n",
       "        [  551,   641]],\n",
       "\n",
       "       [[26900,     0],\n",
       "        [   11,     0]],\n",
       "\n",
       "       [[25831,   289],\n",
       "        [  318,   473]],\n",
       "\n",
       "       [[25602,   318],\n",
       "        [  350,   641]],\n",
       "\n",
       "       [[26051,   484],\n",
       "        [  254,   122]],\n",
       "\n",
       "       [[26900,     0],\n",
       "        [   11,     0]],\n",
       "\n",
       "       [[25927,   610],\n",
       "        [  217,   157]],\n",
       "\n",
       "       [[26900,     0],\n",
       "        [   11,     0]],\n",
       "\n",
       "       [[25497,   961],\n",
       "        [  121,   332]],\n",
       "\n",
       "       [[26605,     0],\n",
       "        [  306,     0]],\n",
       "\n",
       "       [[26561,     0],\n",
       "        [  350,     0]],\n",
       "\n",
       "       [[26900,     0],\n",
       "        [   11,     0]],\n",
       "\n",
       "       [[25641,   500],\n",
       "        [  252,   518]],\n",
       "\n",
       "       [[26035,   428],\n",
       "        [  292,   156]],\n",
       "\n",
       "       [[25933,   627],\n",
       "        [  201,   150]],\n",
       "\n",
       "       [[25495,   152],\n",
       "        [ 1056,   208]],\n",
       "\n",
       "       [[26710,     0],\n",
       "        [  201,     0]],\n",
       "\n",
       "       [[26207,   280],\n",
       "        [  316,   108]],\n",
       "\n",
       "       [[26900,     0],\n",
       "        [   11,     0]],\n",
       "\n",
       "       [[25807,   732],\n",
       "        [  145,   227]],\n",
       "\n",
       "       [[26900,     0],\n",
       "        [   11,     0]],\n",
       "\n",
       "       [[25941,   551],\n",
       "        [  258,   161]],\n",
       "\n",
       "       [[25660,   276],\n",
       "        [  334,   641]],\n",
       "\n",
       "       [[26566,     0],\n",
       "        [  345,     0]],\n",
       "\n",
       "       [[25390,   277],\n",
       "        [  603,   641]],\n",
       "\n",
       "       [[25152,   670],\n",
       "        [  625,   464]],\n",
       "\n",
       "       [[26062,   140],\n",
       "        [  487,   222]],\n",
       "\n",
       "       [[26486,     0],\n",
       "        [  425,     0]],\n",
       "\n",
       "       [[26771,     0],\n",
       "        [  140,     0]]])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multilabel_confusion_matrix(y, svm_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yxin/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/yxin/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/yxin/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/yxin/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/yxin/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.08759933, 0.23890848, 0.40580249, 0.41075749, 0.19336192])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(clf_svm, x, y, scoring='accuracy',cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.09850305, 0.24633377, 0.4041287 , 0.42453006, 0.19541302])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(clf_linsvm, x, y, scoring='accuracy',cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yxin/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.39628869775904857"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y, lin_pred,average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4043405159517015"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y, svm_pred,average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.42499349708297723"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_svm.score(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4150347441566646"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_linsvm.score(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2803607623540877"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_accuracy_score(y, svm_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2877566726729404"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_accuracy_score(y, lin_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26911, 26)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skmultilearn.problem_transform import BinaryRelevance\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = BinaryRelevance(classifier = SVC(probability=True),\n",
    "    require_dense = [False, True])\n",
    "\n",
    "classifier.fit(x.to_numpy(), y.to_numpy())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
