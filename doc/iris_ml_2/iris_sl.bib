%% This BibTeX bibliography file was created using BibDesk.
%% https://bibdesk.sourceforge.io/

%% Created for Yufeng Xin at 2021-11-14 22:35:50 -0500 


%% Saved with string encoding Unicode (UTF-8) 



@article{10.1371/journal.pone.0254720,
	abstract = {Handling missing values is a crucial step in preprocessing data in Machine Learning. Most available algorithms for analyzing datasets in the feature selection process and classification or estimation process analyze complete datasets. Consequently, in many cases, the strategy for dealing with missing values is to use only instances with full data or to replace missing values with a mean, mode, median, or a constant value. Usually, discarding missing samples or replacing missing values by means of fundamental techniques causes bias in subsequent analyzes on datasets. Aim: Demonstrate the positive impact of multivariate imputation in the feature selection process on datasets with missing values. Results: We compared the effects of the feature selection process using complete datasets, incomplete datasets with missingness rates between 5 and 50%, and imputed datasets by basic techniques and multivariate imputation. The feature selection algorithms used are well-known methods. The results showed that the datasets imputed by multivariate imputation obtained the best results in feature selection compared to datasets imputed by basic techniques or non-imputed incomplete datasets. Conclusions: Considering the results obtained in the evaluation, applying multivariate imputation by MICE reduces bias in the feature selection process.},
	author = {Mera-Gaona, Maritza AND Neumann, Ursula AND Vargas-Canas, Rubiel AND L{\'o}pez, Diego M.},
	date-added = {2021-11-14 16:10:55 -0500},
	date-modified = {2021-11-14 22:34:12 -0500},
	journal = {PLOS ONE},
	month = {07},
	number = {7},
	pages = {1-28},
	publisher = {Public Library of Science},
	title = {Evaluating the impact of multivariate imputation by MICE in feature selection},
	volume = {16},
	year = {2021},
	bdsk-url-1 = {https://doi.org/10.1371/journal.pone.0254720}}

@article{JSSv045i03,
	abstract = {The R package &amp;lt;b&amp;gt;mice&amp;lt;/b&amp;gt; imputes incomplete multivariate data by chained equations. The software mice 1.0 appeared in the year 2000 as an S-PLUS library, and in 2001 as an R package. mice 1.0 introduced predictor selection, passive imputation and automatic pooling. This article documents mice, which extends the functionality of mice 1.0 in several ways. In &amp;lt;b&amp;gt;mice&amp;lt;/b&amp;gt;, the analysis of imputed data is made completely general, whereas the range of models under which pooling works is substantially extended. &amp;lt;b&amp;gt;mice&amp;lt;/b&amp;gt; adds new functionality for imputing multilevel data, automatic predictor selection, data handling, post-processing imputed values, specialized pooling routines, model selection tools, and diagnostic graphs. Imputation of categorical data is improved in order to bypass problems caused by perfect prediction. Special attention is paid to transformations, sum scores, indices and interactions using passive imputation, and to the proper setup of the predictor matrix. &amp;lt;b&amp;gt;mice&amp;lt;/b&amp;gt; can be downloaded from the Comprehensive R Archive Network. This article provides a hands-on, stepwise approach to solve applied incomplete data problems.},
	author = {van Buuren, Stef and Groothuis-Oudshoorn, Karin},
	date-added = {2021-11-14 15:07:23 -0500},
	date-modified = {2021-11-14 22:33:58 -0500},
	journal = {Journal of Statistical Software},
	number = {3},
	pages = {1--67},
	title = {mice: Multivariate Imputation by Chained Equations in R},
	volume = {45},
	year = {2011},
	bdsk-url-1 = {https://www.jstatsoft.org/index.php/jss/article/view/v045i03},
	bdsk-url-2 = {https://doi.org/10.18637/jss.v045.i03}}

@conference{iris:ictc21,
	address = {Jeju Island, South Korea},
	author = {Y. Xin and S. Fu and A. Mandal and I. Baldin and R. Tanaka and M. Rynge and K. Vahi and E. Deelman and I. Abhinit and V. Welch},
	booktitle = {12th International Conference on Information and Communication Technology Convergence},
	date-added = {2021-11-13 19:51:50 -0500},
	date-modified = {2021-11-13 21:06:56 -0500},
	month = {Oct.},
	organization = {IEEE},
	title = {ROOT CAUSE ANALYSIS OF DATA INTEGRITY ERRORS IN NETWORKED SYSTEMS WITH INCOMPLETE INFORMATION},
	year = {2021}}

@article{DONDERS20061087,
	abstract = {In most situations, simple techniques for handling missing data (such as complete case analysis, overall mean imputation, and the missing-indicator method) produce biased results, whereas imputation techniques yield valid results without complicating the analysis once the imputations are carried out. Imputation techniques are based on the idea that any subject in a study sample can be replaced by a new randomly chosen subject from the same source population. Imputation of missing data on a variable is replacing that missing by a value that is drawn from an estimate of the distribution of this variable. In single imputation, only one estimate is used. In multiple imputation, various estimates are used, reflecting the uncertainty in the estimation of this distribution. Under the general conditions of so-called missing at random and missing completely at random, both single and multiple imputations result in unbiased estimates of study associations. But single imputation results in too small estimated standard errors, whereas multiple imputation results in correctly estimated standard errors and confidence intervals. In this article we explain why all this is the case, and use a simple simulation study to demonstrate our explanations. We also explain and illustrate why two frequently used methods to handle missing data, i.e., overall mean imputation and the missing-indicator method, almost always result in biased estimates.},
	author = {A. Rogier T. Donders and Geert J.M.G. {van der Heijden} and Theo Stijnen and Karel G.M. Moons},
	date-added = {2021-11-13 15:15:54 -0500},
	date-modified = {2021-11-14 22:35:47 -0500},
	issn = {0895-4356},
	journal = {Journal of Clinical Epidemiology},
	keywords = {Missing data, Single imputation, Multiple imputation, Indicator method, Bias, Precision},
	number = {10},
	pages = {1087-1091},
	title = {Review: A gentle introduction to imputation of missing values},
	volume = {59},
	year = {2006},
	bdsk-url-1 = {https://www.sciencedirect.com/science/article/pii/S0895435606001971},
	bdsk-url-2 = {https://doi.org/10.1016/j.jclinepi.2006.01.014}}

@article{Awan2021ImputationOM,
	author = {Saqib Ejaz Awan and Mohammed Bennamoun and Ferdous Sohel and Frank M. Sanfilippo and Girish Dwivedi},
	date-added = {2021-11-12 11:02:13 -0500},
	date-modified = {2021-11-12 11:02:13 -0500},
	journal = {Neurocomputing},
	pages = {164-171},
	title = {Imputation of Missing Data with Class Imbalance using Conditional Generative Adversarial Networks},
	volume = {453},
	year = {2021}}

@article{Yoon2018GAINMD,
	author = {Jinsung Yoon and James Jordon and Mihaela van der Schaar},
	date-added = {2021-11-12 11:01:05 -0500},
	date-modified = {2021-11-12 11:01:05 -0500},
	journal = {ArXiv},
	title = {GAIN: Missing Data Imputation using Generative Adversarial Nets},
	volume = {abs/1806.02920},
	year = {2018}}

@article{missingdata:sensor:20,
	author = {Du, Jinghan and Hu, Minghua and Zhang, Weining},
	date-added = {2021-11-12 10:50:49 -0500},
	date-modified = {2021-11-12 10:51:16 -0500},
	doi = {10.1109/JSEN.2020.3009265},
	journal = {IEEE Sensors Journal},
	number = {23},
	pages = {13984-13998},
	title = {Missing Data Problem in the Monitoring System: A Review},
	volume = {20},
	year = {2020},
	bdsk-url-1 = {https://doi.org/10.1109/JSEN.2020.3009265}}

@article{tcp:ccr2000,
	abstract = {Traces of Internet packets from the past two years show that between 1 packet in 1,100 and 1 packet in 32,000 fails the TCP checksum, even on links where link-level CRCs should catch all but 1 in 4 billion errors. For certain situations, the rate of checksum failures can be even higher: in one hour-long test we observed a checksum failure of 1 packet in 400. We investigate why so many errors are observed, when link-level CRCs should catch nearly all of them.We have collected nearly 500,000 packets which failed the TCP or UDP or IP checksum. This dataset shows the Internet has a wide variety of error sources which can not be detected by link-level checks. We describe analysis tools that have identified nearly 100 different error patterns. Categorizing packet errors, we can infer likely causes which explain roughly half the observed errors. The causes span the entire spectrum of a network stack, from memory errors to bugs in TCP.After an analysis we conclude that the checksum will fail to detect errors for roughly 1 in 16 million to 10 billion packets. From our analysis of the cause of errors, we propose simple changes to several protocols which will decrease the rate of undetected error. Even so, the highly non-random distribution of errors strongly suggests some applications should employ application-level checksums or equivalents.},
	address = {New York, NY, USA},
	author = {Stone, Jonathan and Partridge, Craig},
	date-added = {2021-06-07 14:14:01 -0400},
	date-modified = {2021-06-07 14:14:32 -0400},
	doi = {10.1145/347057.347561},
	issn = {0146-4833},
	issue_date = {October 2000},
	journal = {SIGCOMM Comput. Commun. Rev.},
	month = aug,
	number = {4},
	numpages = {11},
	pages = {309--319},
	publisher = {Association for Computing Machinery},
	title = {When the CRC and TCP Checksum Disagree},
	url = {https://doi.org/10.1145/347057.347561},
	volume = {30},
	year = {2000},
	bdsk-url-1 = {https://doi.org/10.1145/347057.347561}}

@inproceedings{swip:pearc:2019,
	acmid = {3332222},
	address = {New York, NY},
	articleno = {17},
	author = {Rynge, Mats and Vahi, Karan and Deelman, Ewa and Mandal, Anirban and Baldin, Ilya and Bhide, Omkar and Heiland, Randy and Welch, Von and Hill, Raquel and Poehlman, William L. and Feltus, F. Alex},
	booktitle = {Practice and Experience in Advanced Research Computing on Rise of the Machines Learning ({PEARC})},
	date-added = {2021-05-25 21:14:47 -0400},
	date-modified = {2021-05-25 21:14:47 -0400},
	doi = {10.1145/3332186.3332222},
	isbn = {978-1-4503-7227-5},
	location = {Chicago, IL, USA},
	numpages = {8},
	title = {Integrity Protection for Scientific Workflow Data: Motivation and Initial Experiences},
	year = {2019},
	bdsk-url-1 = {http://doi.acm.org/10.1145/3332186.3332222},
	bdsk-url-2 = {https://doi.org/10.1145/3332186.3332222}}

@webpage{facebook:cpu:2021,
	date-added = {2021-05-25 21:10:33 -0400},
	date-modified = {2021-05-25 21:11:25 -0400},
	lastchecked = {May 25, 2021},
	url = {https://www.nextplatform.com/2021/03/01/facebook-architects-around-silent-data-corruption/},
	bdsk-url-1 = {https://www.nextplatform.com/2021/03/01/facebook-architects-around-silent-data-corruption/}}

@article{Jung2019HighPerformanceEI,
	author = {Eun-Sung Jung and Si Liu and R. Kettimuthu and Sungwook Chung},
	date-added = {2021-05-25 20:58:40 -0400},
	date-modified = {2021-05-25 20:58:40 -0400},
	journal = {IEICE Trans. Inf. Syst.},
	pages = {1478-1488},
	title = {High-Performance End-to-End Integrity Verification on Big Data Transfer},
	volume = {102-D},
	year = {2019}}

@inproceedings{impaptr:ase20,
	author = {Wang, Hao and Rong, Guoping and Xu, Yangchen and You, Yong},
	booktitle = {2020 35th IEEE/ACM International Conference on Automated Software Engineering (ASE)},
	date-added = {2021-05-24 21:21:41 -0400},
	date-modified = {2021-05-24 21:22:08 -0400},
	pages = {1307-1311},
	title = {ImpAPTr: A Tool For Identifying The Clues To Online Service Anomalies},
	year = {2020}}

@article{Boulle:2019aa,
	abstract = {Companies want to extract value from their relational databases. This is the aim of relational data mining. Propositionalization is one possible approach to relational data mining. Propositionalization adds new attributes, called features, to the main table, leading to an attribute-value representation, a single table, on which a propositional learner can be applied. However, current relational databases are large and composed of mixed, numerical and categorical, data. Moreover, the specificity of relational data is to involve one-to-many relationships. As an example of such data, consider customers purchasing products: each customer can purchase several products. Therefore, there is a need for techniques able to learn complex aggregates. Learning such features means to explore a combinatorial, possibly infinite, space and such an approach is prone to overfitting. We introduce a propositionalization approach dedicated to a robust Bayesian classifier. It efficiently samples a given number of features in the language bias, following a distribution over the complex aggregates. This distribution is also used to penalize complex aggregates in the regularization of the robust Bayesian classifier. Experiments show that it performs better than state-of-the-art methods on most investigated benchmarks and can deal with large datasets more easily. A new real, large, mixed relational dataset is introduced which confirms the ability of our approach to learn complex aggregates.},
	author = {Boull{\'e}, Marc and Charnay, Cl{\'e}ment and Lachiche, Nicolas},
	da = {2019/02/01},
	date-added = {2020-12-03 11:43:52 -0500},
	date-modified = {2020-12-03 11:43:52 -0500},
	doi = {10.1007/s10994-018-5746-9},
	id = {Boull{\'e}2019},
	isbn = {1573-0565},
	journal = {Machine Learning},
	number = {2},
	pages = {229--266},
	title = {A scalable robust and automatic propositionalization approach for Bayesian classification of large mixed numerical and categorical data},
	ty = {JOUR},
	url = {https://doi.org/10.1007/s10994-018-5746-9},
	volume = {108},
	year = {2019},
	bdsk-url-1 = {https://doi.org/10.1007/s10994-018-5746-9}}

@book{RW06:GP,
	address = {Cambridge, Mass.},
	author = {C. E. Rasmussen and C. K. I. Williams},
	date-added = {2020-10-12 19:31:50 -0400},
	date-modified = {2020-10-12 19:33:03 -0400},
	publisher = {MIT Press},
	title = {Gaussian processes for machine learning},
	year = {2006}}

@article{sf:on:2018,
	author = {A. P. {Vela} and B. {Shariati} and M. {Ruiz} and F. {Cugini} and A. {Castro} and H. {Lu} and R. {Proietti} and J. {Comellas} and P. {Castoldi} and S. J. B. {Yoo} and L. {Velasco}},
	date-added = {2020-08-02 13:03:01 -0400},
	date-modified = {2020-08-02 13:03:28 -0400},
	journal = {IEEE/OSA Journal of Optical Communications and Networking},
	number = {1},
	pages = {A27-A36},
	title = {Soft failure localization during commissioning testing and lightpath operation},
	volume = {10},
	year = {2018}}

@article{gp:on:2018,
	author = {T. {Panayiotou} and S. P. {Chatzis} and G. {Ellinas}},
	date-added = {2020-08-02 13:00:02 -0400},
	date-modified = {2020-08-02 13:01:14 -0400},
	journal = {IEEE/OSA Journal of Optical Communications and Networking},
	number = {3},
	pages = {162-173},
	title = {Leveraging statistical machine learning to address failure localization in optical networks},
	volume = {10},
	year = {2018}}
