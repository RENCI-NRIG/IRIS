We studied the Root Cause Analysis (RCA) problem for integrity error diagnosis that is critical to reliably operate large-scale distributed applications. The main challenges of the incomplete network state information, low probabilistic nature of gray failures, and infeasible scalable system model have hindered the development of efficient diagnostic technologies and tools for systems of realistic scales. Without the need for an accurate system model, the emerging machine learning techniques have inspired much research interest in network system RCA recently, especially for large-scale data center networks.

In this study, we target the integrity error RCA for large-scale distributed application systems deployed over a wide area multi-domain network environment. We formulated this problem as a multi-class classification problem. Our main hypothesis is that the mapping between the end host level flow statistics and the possible network component failures can be learned and inferred from a sufficiently large amount of labeled data via training efficient supervised machine learning models. While the technical challenges are similar to the general system RCA problem, this environment poses much greater challenge in collecting sufficient (labeled) training data due to the technical and administrative barriers.  

We thereafter built a high-fidelity emulation environment in a Cloud testbed that allows creating virtual systems to emulate arbitrary large-scale networks and run the real application software. We further developed a suite of software tools to automate the whole analysis workflow that includes virtual network creation, routing control plane configuration, integrity error injection, experimental data transfer and integrity check, and training data collection. This environment makes experiments highly repeatable and reproducible and and trained models have the potential to be directly used in the production systems.   

We then conducted extensive RCA ML model analysis with the harvested data from emulating a data transfer workflow system over a wide-area multi-domain network with many end hosts. We evaluated several ML model variants from three families of multi-class classification models, Bayesian inference, SVM, and Decision Tree. For inference, we defined network-wide aggregated data flow as the input and a Top-k accuracy metric based on class probability distribution. We specifically studied the impacts of different combinations of flow lever training data coverage in terms of end host pairs and mixed numerical and categorical features on the model performance, which also reflects different data availability scenarios in realistic system settings. We further looked into the inherited data imbalance in the training data set. The results demonstrate the efficacy the proposed ML approach and extremely high root cause inference accuracy can be achieved with a Random Forest model and oversampling method.    

For our future work, we plan to experiment with networks of orders of magnitude larger scale with different graph characteristics with finer tuned ML models. In theory, end host level flow information only is not sufficient to provide full network coverage to achieve high accuracy for RCA. We need to explore efficient algorithmic approaches to find minimum monitoring capability in chosen locations inside the network. Another interesting direction is to recognize that different types of devices in the network have different probabilistic error behaviors, which suggests a probabilistic ML approaches are worth of exploration.

Last but not least, we are working on integrating the developed ML tools and models with the Pegasus workflow system. Our ultimate goal is to develop a ML-based RCA software as part of the production application systems for real-time error diagnosis with high accuracy.

