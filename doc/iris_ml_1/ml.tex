Our targeted networks are of multi-domain nature where the RCA granularity can be limited to individual domains instead of individual routers inside a domain, which are totally unknown to the outside. The network can be represented as a simple graph $G(V,E)$ where $V$ is the set of nodes that includes $H$ end hosts and $R$ routers. $E$ is the set of links. We say a file transfer succeeds when it incurs no integrity errors. 

In general, the problem at hand can be concisely represented by the following formula.
\begin{flalign}\label{eq:prob}
\begin{aligned}
&Probability(File\ i\ succeeds) =\\
&f(F_i, \prod_{j \in P_i}Probability(component\ j\ is\ normal) )
\end{aligned}
\end{flalign}

A path $P_i$ that a file transfer (flow) $i$ traverses consists of origin node $H_i^o$, a set of links where each $e_i^j\in E$ has two interfaces $e_i^t$ and $e_i^r$ on the route, and destination node $H_i^d$. As our main concern is if a file is corrupted rather than packet losses, the file characteristics, $F_i$, eg, the file size, transfer time, etc. may play an important role. We emphasize again that the components ($j$) of $P\ i$ that file transfer $i$ traverses is unknown except for its two end hosts $H_i^o$ and $H_i^d$. And a large amount of data transfer flows are needed to generate sufficient training data since our targeted grey failure, the integrity error, has a very low probability (often in the order of $10^{-3}$).

We model our problem as a multi-class classification problem where the labels are defined as all the nodes and links that may incur integrity errors and the features are flow level characteristics that include source, destination, size, transfer time, throughput, whether a flow is corrupted, missed, or retried, etc. In general, the training process takes as input two arrays: an array $X$ of size $[n_{samples}, n_{features}]$ holding the training samples, and an array $y$ of class labels of size $[n_{samples}]$. The total number of labels $L$ equals to the number of the link interfaces and the end hosts in the topology.

In this study, we focus on RCA analysis with failure data only, \ie, the data sets used in training only contains those corrupted files transfers with fault labels that are extracted from the raw data collected from the experiment that consists of both successful data transfers. This non-probabilistic approach not only bears its own technical merit but also reflects the reality that only failure events are going to be reported in applications. Due to the low probability nature of the integrity errors, it is not economically viable to save all data transfer monitoring statistics as the majority of them are normally successful. In the follow-up study, we will adopt a probabilistic approach that takes the statistic distribution of file transfer corruption and network component failures.      

There are a large number of different supervised ML models and associated parameters to be tuned. Our data sets introduce mixed numerical and categorical features as well as data imbalance. After evaluating several model variants from the families of 
{\it Decision Tree}, {\it Support Vector Machine (SVM)}, and {\it Bayesian Networks (BN)} with training data using the popular Scikit-learn library~\cite{Scikit:web}, we chose the random forest model in our system because it results in the best performance in terms of inference accuracy and training time.

\subsection{Aggregated flows and inference accuracy}
One key observation is that an erratic link may cause integrity errors on all data transfer paths traversing it. While the training data is collected in the form of individually labeled flows, the inference can be done in the unit of all flows that are corrupted at a time since we only consider the single failure scenario. The models are trained with the labeled flow data.  For inference, we consider two different methods: {\it Flow} that just uses individual flow as the input and {\it Aggregated Flow} for which we generated a new data set that all corrupted file transfer flows at a time are aggregated as one input data sample. In the former case, the accuracy is computed on a per flow base. In the latter case, if all the flows in a data set are labeled by $L$ labels, they will be aggregated into $L$ samples to be tested against the trained model. The total number of correct label inference divided by $L$ is defined as the accuracy.

\subsection{Top-$k$ classification accuracy} 
Since we assume training data from data transfer flows only between the end hosts, it doesn't satisfy the necessary condition presented in~\cite{netbouncer:nsdi18}. The conventional classification on a single label inference from the training models performs relatively poorly in terms of accuracy and F-score. In practice, it would be very useful if the model can produce a small set of highly likely causes for the operators to zoom in. Most of the ML models, when used to infer a test sample, actually generate the probability distribution over all the classes. Therefore we can use a Top-$k$ Accuracy metric in evaluation, for which a prediction is defined as correct as long as the set of $k$ labels of highest probability in the classification results contains the correct label of the sample. Both decisions tree and BN models natively support the classification probability output. 

\subsection{Features}
As explained on Equation~\ref{eq:prob}, for a data sample, the feature set could consist of both path features and file transfer features. In our model, we only consider the features that are possible for the application to collect at the end hosts.
So only the end host information is included for the path features because we assume the other network elements on the file transfer paths are unknown. 
The file transfer features include both numerical characteristics like file size and transfer throughput , and categorical features like correctness of integrity checksum and presence of retransmission. 

The impacts of the file transfer features are two-folded. On one hand, the bigger file size may incur a higher probability of file corruption and lower throughput may imply more TCP retransmission caused by corrupted packets, which may help with the RCA performance. On the other hand, different machine learning models perform differently when dealing with a mixture of numerical and categorical features. In reality, there are always engineering and policy limits on obtaining certain 
features for application users in a network. Therefore it is important to study the model performance when only a subset of features are available. Therefore we study two scenarios of different feature sets: {\it No File Features} when the numerical file size and transfer throughput information is not available and {\it All Features} when it is available.

\subsection{Error Asymmetry and Data Imbalance} 
\label{sub:ml:imbalance}
A leading factor that affects the performance of multi-class classification models, is the data set imbalance. When data samples from certain classes (called {\it majority classes}) outnumber those from other classes, the trained models will be highly skewed toward the major classes, which will significantly lower the prediction accuracy. By the nature of integrity error simulation, the file transfer failures caused by faulty network interfaces are more frequent than those caused by the faulty end hosts. And between the two interfaces on a link, the one on the receiving side of a file transfer over TCP has a much higher chance to corrupt the file than the one on the transmitting side. Therefore the raw data we collected is oversampled on a subset of the network interface classes and significantly undersampled on the end host classes. 